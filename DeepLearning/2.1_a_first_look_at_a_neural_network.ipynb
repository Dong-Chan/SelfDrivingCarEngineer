{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first look at a neural network\n",
    "We will now take a look at a first concrete example of a neural network, which makes use of the Python library Keras to learn to classify hand-written digits.\n",
    "\n",
    "The MNIST dataset comes pre-loaded in Keras, in the form of a set of four Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = train_images[4, 7:-7: , 7:-7]\n",
    "digit.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAANvUlEQVR4nO3df4xV9ZnH8c9HplikpYoQUxiyo9G4IaZdG1Jta6oprlCLTv9YDQYMbIn7j7ultYZglDRr1Kxp07RkaxtjBaNETagVY9oCa1txzZaAP2L5YStrq6IjM9LYIkVx4rN/3EszTAG753vumVue9yuZzP318DwzmQ/n3nPPuV9HhAAc/04Y6wEANIOwA0kQdiAJwg4kQdiBJHqabDZlypTo6+trsuVxYf/+/ZVr9+7dW9T7rbfeKqo/cOBAUX2J3t7eyrXjx48v6r1v377Ktaeeemrl2oGBAb355ps+0n2Nhr2vr09bt25tsuVxYfPmzZVr77333qLemzZtKqrftm1bUX2J6667rnLttGnTino/8cQTlWuvvvrqyrWLFy8+6n08jQeSIOxAEoQdSKIo7Lbn2v617V22l9c1FID6VQ677XGSvivp85JmSrrK9sy6BgNQr5It+ycl7YqIFyPioKQHJPXXMxaAupWEfbqkV0Zc392+7TC2/8X2Vttbh4aGCtoBKNHxHXQRcWdEzIqIWVOnTu10OwBHURL2VyXNGHG9t30bgC5UEvYtks6yfbrt8ZLmS3qknrEA1K3y4bIRMWz7XyWtlzRO0t0Rsb22yQDUqujY+Ij4saQf1zQLgA7iCDogCcIOJNHoKa5ZPfjgg0X1S5curVxbemxD6acPX3TRRZVr33jjjaLe119/fVF9iZLfW8nPvWfPnqPex5YdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpTXIeHh4vqt2zZUrn2mmuuKepdsmTzhRdeWNR7xYoVRfUXXHBB5dp33nmnqPeVV15ZuXb9+vVFvUvMmjWrcu2TTz551PvYsgNJEHYgCcIOJEHYgSRKVnGdYfvntnfY3m67+gelAei4kr3xw5K+FhFP2/6wpKdsb4yIHTXNBqBGlbfsETEQEU+3L++TtFNHWMUVQHeo5TW77T5J50rafIT7WLIZ6ALFYbf9IUk/lPSViPjj6PtZshnoDkVht/0BtYK+JiIeqmckAJ1Qsjfekn4gaWdEfKu+kQB0QsmW/TOSrpb0OdvPtr8urWkuADUrWZ/9vyW5xlkAdBBH0AFJEHYgiTTns993331F9UuWLKlpkv+/Sy65pHJt6XLRkyZNKqovUTr7WJ6TPmPGjMq1ixYtqlx7rL9ztuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/qZOcb3pppsq1952221FvVsfuVfNtddeW9T7lltuqVw7lqeolrr11lvHeoTKVq5cWbm25FOYe3qOHmm27EAShB1IgrADSRB2IIk6ln8aZ/sZ24/WMRCAzqhjy75UrRVcAXSx0rXeeiV9QdJd9YwDoFNKt+zflrRM0ntHewBLNgPdoWRhx3mSBiPiqWM9jiWbge5QurDj5bZ/J+kBtRZ4LFuJAUDHVA57RNwQEb0R0SdpvqSfRcTC2iYDUCveZweSqOVEmIj4haRf1PFvAegMtuxAEoQdSKLR89kHBgZ08803V64vOSf9xBNPrFwrSXPmzKlce/vttxf1njBhQlF9ibfffruofsOGDZVrX3rppaLeEVG5dsWKFUW9+/v7i+o7gS07kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiUZPcR0cHNQdd9xRub5k2eSSU1Ql6eGHHy6qHyu7du0qql+wYEFR/datW4vqS1xxxRWVa5ctW1bjJN2BLTuQBGEHkiDsQBKEHUiidGHHk22vtf287Z22P1XXYADqVbo3/juSfhoR/2R7vKSTapgJQAdUDrvtj0j6rKTFkhQRByUdrGcsAHUreRp/uqQhSatsP2P7LtsTRz9o5JLN77131JWdAXRYSdh7JH1C0vci4lxJ+yUtH/2gkUs2n3AC+wOBsVKSvt2SdkfE5vb1tWqFH0AXKlmy+XVJr9g+u33TbEk7apkKQO1K98b/m6Q17T3xL0r65/KRAHRCUdgj4llJs+oZBUAnsccMSIKwA0k0ej778PCwhoaGmmz5ZytXriyqHxwcrFy7atWqot7r1q2rXLt9+/ai3vv27SuqL/kMgtK3ahcuXFi5duLEvzhk5G8eW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IotHz2Xt6ejRlypTK9SXnlPf19VWulcrOyx5L06dPL6qfNGlSUf1rr71Wubbkb0WSLrvssqL64w1bdiAJwg4kQdiBJEqXbP6q7e22t9m+3/YH6xoMQL0qh932dElfljQrIs6RNE7S/LoGA1Cv0qfxPZIm2O5Ra2326rteAXRUyVpvr0r6pqSXJQ1I+kNEbBj9OJZsBrpDydP4UyT1q7VO+zRJE23/xQd1s2Qz0B1K0nexpN9GxFBEvCvpIUmfrmcsAHUrCfvLks63fZJbh5fNlrSznrEA1K3kNftmSWslPS3pV+1/686a5gJQs9Ilm78u6es1zQKgg9hjBiRB2IEkGj3F9cwzz9Tq1asr18+bN69y7d69eyvXSq3Zq+rv7y/qvXjx4sq1kydPLuo9f37ZQZElp7iW9sbh2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo2ezz5x4kSdd955leuHhoZqnCaHTZs2FdU//vjjRfUlS12fccYZRb1xOLbsQBKEHUiCsANJvG/Ybd9te9D2thG3Tba90fYL7e+ndHZMAKX+mi37aklzR922XNJjEXGWpMfa1wF0sfcNe0RskvT7UTf3S7qnffkeSV+sdywAdav6mv20iBhoX35d0mlHe+DIJZt56wwYO8U76CIiJMUx7v/zks1Tp04tbQegoqph32P7o5LU/j5Y30gAOqFq2B+RtKh9eZGkdfWMA6BT/pq33u6X9D+Szra92/YSSf8h6R9tvyDp4vZ1AF3sfY+Nj4irjnLX7JpnAdBBHEEHJEHYgSQaPcUVzTtw4EBRfckpqqX1LNlcL7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATnsx/n5syZM9YjoEuwZQeSIOxAEoQdSKLqks3fsP287eds/8j2yR2dEkCxqks2b5R0TkR8TNJvJN1Q81wAalZpyeaI2BARw+2rv5TU24HZANSojtfsX5L0kxr+HQAdVBR22zdKGpa05hiPYX12oAtUDrvtxZLmSVrQXqP9iFifHegOlY6gsz1X0jJJF0bEn+odCUAnVF2y+T8lfVjSRtvP2v5+h+cEUKjqks0/6MAsADqII+iAJAg7kASnuB7n1q9fP9YjoEuwZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkfIwPhq2/mT0k6aVjPGSKpDcaGofe9D4ee/9dRBzxY5wbDfv7sb01ImbRm970rh9P44EkCDuQRLeF/U5605vendFVr9kBdE63bdkBdAhhB5LoirDbnmv717Z32V7eYN8Ztn9ue4ft7baXNtV7xAzjbD9j+9GG+55se63t523vtP2pBnt/tf373mb7ftsf7HC/u20P2t424rbJtjfafqH9/ZQGe3+j/Xt/zvaPbJ/cid6jjXnYbY+T9F1Jn5c0U9JVtmc21H5Y0tciYqak8yVd22DvQ5ZK2tlwT0n6jqSfRsTfS/p4UzPYni7py5JmRcQ5ksZJmt/htqslzR1123JJj0XEWZIea19vqvdGSedExMck/UbSDR3qfZgxD7ukT0raFREvRsRBSQ9I6m+icUQMRMTT7cv71PqDn95Eb0my3SvpC5Luaqpnu+9HJH1W7QU6I+JgRLzZ4Ag9kibY7pF0kqTXOtksIjZJ+v2om/sl3dO+fI+kLzbVOyI2RMRw++ovJfV2ovdo3RD26ZJeGXF9txoM3CG2+ySdK2lzg22/rdY69+812FOSTpc0JGlV+yXEXbYnNtE4Il6V9E1JL0sakPSHiNjQRO9RTouIgfbl1yWdNgYzSNKXJP2kiUbdEPYxZ/tDkn4o6SsR8ceGes6TNBgRTzXRb5QeSZ+Q9L2IOFfSfnXuaexh2q+N+9X6D2eapIm2FzbR+2ii9f5z4+9B275RrZeSa5ro1w1hf1XSjBHXe9u3NcL2B9QK+pqIeKipvpI+I+ly279T66XL52zf11Dv3ZJ2R8ShZzFr1Qp/Ey6W9NuIGIqIdyU9JOnTDfUeaY/tj0pS+/tgk81tL5Y0T9KCaOhgl24I+xZJZ9k+3fZ4tXbWPNJEY9tW63Xrzoj4VhM9D4mIGyKiNyL61PqZfxYRjWzhIuJ1Sa/YPrt902xJO5rordbT9/Ntn9T+/c/W2OygfETSovblRZLWNdXY9ly1Xr5dHhF/aqqvImLMvyRdqtZeyf+VdGODfS9Q6+nbc5KebX9dOgY//0WSHm245z9I2tr+2R+WdEqDvf9d0vOStkm6V9KJHe53v1r7B95V61nNEkmnqrUX/gVJ/yVpcoO9d6m1n+rQ39z3m/i9c7gskEQ3PI0H0ADCDiRB2IEkCDuQBGEHkiDsQBKEHUji/wBiPfzAl9VSCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workflow will be follow: first we will present our neural network with the training data, train_images and train_labels. The network will then learn to associate images and labels. Finally, we will ask the network to produce predications for test_images, and we will verify if these predictions match the labels from test_labels.\n",
    "\n",
    "Let's build our network \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
    "\n",
    "    A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be able to steer itself in the right direction.\n",
    "    An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "    Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly classified).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the [0, 1] interval. Previously, our training images for instance were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-2570b65bc10a>:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n",
      "Epoch 1/5\n",
      "  5/469 [..............................] - ETA: 10s - loss: 1.3937 - accuracy: 0.5875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongchan/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  use_legacy_function=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 9s 19ms/step - loss: 0.2543 - accuracy: 0.9261\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.1040 - accuracy: 0.9692\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0682 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0494 - accuracy: 0.9854\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0376 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb204b74c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True) \n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "tset_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9781000018119812\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Our test set accuracy turns out to be 97.8% -- that's quite a bit lower than the training set accuracy. This gap between training accuracy and test accuracy is an example of \"overfitting\", the fact that machine learning models tend to perform worse on new data than on their training data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
